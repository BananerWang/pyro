{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood-free inference in non-Gaussian stochastic volatility models\n",
    "\n",
    "This tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from matplotlib import pyplot\n",
    "from torch.distributions import constraints\n",
    "from pyro import poutine\n",
    "from pyro.infer import EnergyDistance, SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import (AutoDelta, AutoDiagonalNormal, AutoLowRankMultivariateNormal,\n",
    "                                  init_to_median)\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.rc = {'figure.facecolor': (1, 1, 1, 1)}\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(os.path.expanduser(\"~/Downloads/snp500.csv\"))\n",
    "df = pd.read_csv(os.path.expanduser(\"~/Downloads/KO.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(df[\"Close\"]).float()\n",
    "# torch.save(x, os.path.expanduser(\"~/Downloads/snp500_daily_open.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(x)\n",
    "pyplot.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(8, 3), dpi=300)\n",
    "r = (x[1:] / x[:-1]).log()\n",
    "pyplot.plot(r, \"k\", lw=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(8, 3))\n",
    "pyplot.hist(r, bins=200)\n",
    "pyplot.yscale('log')\n",
    "print(\"mean = {}\".format(r.mean()))\n",
    "print(\"std = {}\".format(r.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's fit a single distribution to the returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    stability = pyro.param(\"stability\", torch.tensor(1.9),\n",
    "                           constraint=constraints.interval(0, 2))\n",
    "    skew = pyro.param(\"skew\", torch.tensor(0.), constraint=constraints.interval(-1, 1))\n",
    "    scale = pyro.param(\"scale\", torch.tensor(1.), constraint=constraints.positive)\n",
    "    loc = pyro.param(\"loc\", torch.tensor(0.))\n",
    "    with pyro.plate(\"data\", len(r)):\n",
    "        return pyro.sample(\"r\", dist.Stable(stability, skew, scale, loc), obs=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(1234567890)\n",
    "pyro.enable_validation(True)\n",
    "num_steps = 201\n",
    "optim = ClippedAdam({\"lr\": 0.2, \"lrd\": 0.1 ** (1 / num_steps)})\n",
    "svi = SVI(model, lambda: None, optim, EnergyDistance())\n",
    "losses = []\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step()\n",
    "    losses.append(loss)\n",
    "    if step % 20 == 0:\n",
    "        print(\"step {} loss = {}\".format(step, loss))\n",
    "pyplot.plot(losses)\n",
    "pyplot.yscale('log')\n",
    "for name, value in sorted(pyro.get_param_store().items()):\n",
    "    if value.numel() == 1:\n",
    "        print(\"{} = {}\".format(name, value.squeeze().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = poutine.uncondition(model)().detach()\n",
    "pyplot.figure(figsize=(8, 3), dpi=300)\n",
    "pyplot.hist(samples, bins=200)\n",
    "pyplot.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a poor fit, but that's to be expected since we're mixing all time steps together: we would expect this to be a scale-mixture of distributions (Normal, StudentT, or Stable), but are modeling it as a single distribution (Stable in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling in Pyro\n",
    "\n",
    "Consider a stochastic volatity model of the log returns `r_t` and a latent volatility `h`:\n",
    "$$\n",
    "  \\log h_t = \\delta + \\phi \\log h_{t-1} + \\sigma v_t \\\\\n",
    "  r_t = w_t \\sqrt{h_t}\n",
    "$$\n",
    "Usually $\\sigma v_1$ and $w_t$ are both Gaussian. We will generalize to Student t and Stable distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process(dist.TorchDistribution):\n",
    "    arg_constraints = {}\n",
    "    def __init__(self, size, decay, trans_dist):\n",
    "        self.decay = decay\n",
    "        self.trans_dist = trans_dist\n",
    "        batch_shape = trans_dist.batch_shape\n",
    "        event_shape = (size,)\n",
    "        super().__init__(batch_shape, event_shape)\n",
    "    @property\n",
    "    def support(self):\n",
    "        return self.trans_dist.support\n",
    "    def expand(self, shape):\n",
    "        return Process(\n",
    "            self.event_shape[0],\n",
    "            self.decay,\n",
    "            self.trans_dist.expand(shape))\n",
    "    def log_prob(self, series):\n",
    "        # Effectively unsqueeze self.trans_dist\n",
    "        if isinstance(self.trans_dist, dist.Normal):\n",
    "            trans_dist = dist.Normal(self.trans_dist.loc.unsqueeze(-1),\n",
    "                                     self.trans_dist.scale.unsqueeze(-1))\n",
    "        elif isinstance(self.trans_dist, dist.StudentT):\n",
    "            trans_dist = dist.StudentT(self.trans_dist.df.unsqueeze(-1),\n",
    "                                       self.trans_dist.loc.unsqueeze(-1),\n",
    "                                       self.trans_dist.scale.unsqueeze(-1))\n",
    "        else:\n",
    "            raise NotImplementedError(type(self.trans_dist))\n",
    "        diff = series[1:] - series[:-1] * self.decay\n",
    "        return trans_dist.log_prob(diff).sum(-1)\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, process_type=\"normal\", obs_type=\"normal\"):\n",
    "        self.process_type = process_type\n",
    "        self.obs_type = obs_type\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        # We experiment with three types of process noise.\n",
    "        timescale = pyro.sample(\"timescale\", dist.LogNormal(10, 3))\n",
    "        h_decay = (-1 / timescale).exp()\n",
    "        if self.process_type == \"normal\":\n",
    "            h_dist = dist.Normal(0, timescale.rsqrt())\n",
    "        elif self.process_type == \"studentt\":\n",
    "            h_df = pyro.sample(\"h_df\", dist.Gamma(3, 1))\n",
    "            h_dist = dist.StudentT(h_df, 0, timescale.rsqrt())\n",
    "        else:\n",
    "            raise ValueError(\"unsupported process_type: {}\".format(self.process_type))\n",
    "        noise = pyro.sample(\"noise\", Process(len(data), h_decay, h_dist))\n",
    "        if noise.dim() >= 2:\n",
    "            noise = noise.squeeze(-2)\n",
    "        \n",
    "        h_loc = pyro.sample(\"h_loc\", dist.Normal(0, 3))\n",
    "        h_scale = pyro.sample(\"h_scale\", dist.LogNormal(-10, 3))\n",
    "        log_h = h_loc + h_scale * noise\n",
    "\n",
    "        # We experiment with two types of observation noise.\n",
    "        r_loc = pyro.sample(\"r_loc\", dist.Normal(0, 1e-2))\n",
    "        r_scale = log_h.mul(0.5).exp()\n",
    "        if self.obs_type == \"normal\":\n",
    "            r_dist = dist.Normal(r_loc, r_scale)\n",
    "        elif self.obs_type == \"studentt\":\n",
    "            r_df = pyro.sample(\"r_df\", dist.Gamma(3, 1))\n",
    "            r_dist = dist.StudentT(r_df, r_loc, r_scale)\n",
    "        elif self.obs_type == \"stable\":\n",
    "            r_stability = pyro.sample(\"r_stability\", dist.Uniform(0.5, 2.0))\n",
    "            r_skew = pyro.sample(\"r_skew\", dist.Uniform(-1, 1))\n",
    "            r_dist = dist.Stable(r_stability, r_skew, r_scale, r_loc)\n",
    "        else:\n",
    "            raise ValueError(\"unsupported obs_type: {}\".format(self.obs_type))\n",
    "        with pyro.plate(\"time\", len(data)):\n",
    "            r = pyro.sample(\"r\", r_dist, obs=data)\n",
    "\n",
    "        return log_h.detach(), r.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_loc_fn(site):\n",
    "    inits = {\n",
    "        \"h_loc\": r.std().log().mul(2),\n",
    "        \"timescale\": torch.tensor(100.),\n",
    "        \"h_df\": torch.tensor(10.),\n",
    "        \"h_scale\": torch.tensor(1.),\n",
    "        \"r_df\": torch.tensor(10.),\n",
    "        \"r_stability\": torch.tensor(1.9),\n",
    "        \"r_skew\": torch.tensor(0.),\n",
    "        \"r_loc\": torch.tensor(0.),\n",
    "    }\n",
    "    if site[\"name\"] in inits:\n",
    "        return inits[site[\"name\"]]\n",
    "    return init_to_median(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro import poutine\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, guide, data):\n",
    "    trace = poutine.trace(guide).get_trace(data)\n",
    "    with poutine.replay(trace=trace), poutine.uncondition():\n",
    "        return model(data)\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "def add_prediction(model, guide, data):\n",
    "    predictions[model.process_type, model.obs_type] = predict(model, guide, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elbo(model, num_steps=1001):\n",
    "    pyro.clear_param_store()\n",
    "    pyro.set_rng_seed(1234567890)\n",
    "    pyro.enable_validation(True)\n",
    "    guide = AutoDelta(model, init_loc_fn=init_loc_fn)\n",
    "    # guide = AutoDiagonalNormal(model, init_loc_fn=init_loc_fn)\n",
    "    # guide = AutoLowRankMultivariateNormal(model, init_loc_fn=init_loc_fn, rank=8)\n",
    "    optim = ClippedAdam({\n",
    "        \"lr\": 0.02,\n",
    "        \"betas\": (0.9, 0.99),\n",
    "        \"lrd\": 0.1 ** (1 / num_steps),\n",
    "    })\n",
    "    svi = SVI(model, guide, optim, Trace_ELBO())\n",
    "    losses = []\n",
    "    for step in range(num_steps):\n",
    "        loss = svi.step(r)\n",
    "        losses.append(loss)\n",
    "        if step % 50 == 0:\n",
    "            median = guide.median()\n",
    "            print(\"step {} loss = {:0.6g}, timescale = {:0.3g}\".format(\n",
    "                step, loss, median[\"timescale\"].item()))\n",
    "    pyplot.plot(losses)\n",
    "    for name, value in sorted(guide.median().items()):\n",
    "        if value.numel() == 1:\n",
    "            print(\"{} = {}\".format(name, value.squeeze().item()))\n",
    "    add_prediction(model, guide, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Model(\"normal\", \"normal\")\n",
    "train_elbo(model, num_steps=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Model(\"normal\", \"studentt\")\n",
    "train_elbo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Model(\"studentt\", \"normal\")\n",
    "train_elbo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Model(\"studentt\", \"studentt\")\n",
    "train_elbo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_energy(model, num_steps=1001):\n",
    "    pyro.clear_param_store()\n",
    "    pyro.set_rng_seed(1234567890)\n",
    "    pyro.enable_validation(True)\n",
    "    guide = AutoDelta(model, init_loc_fn=init_loc_fn)\n",
    "    # guide = AutoDiagonalNormal(model, init_loc_fn=init_loc_fn)\n",
    "    # guide = AutoLowRankMultivariateNormal(model, init_loc_fn=init_loc_fn, rank=8)\n",
    "    optim = ClippedAdam(lambda name, _: {\n",
    "        \"lr\": 0.1 if name.startswith(\"Auto\") else 0.01,\n",
    "        \"betas\": (0.9, 0.99),\n",
    "        \"lrd\": 0.1 ** (1 / num_steps),\n",
    "    })\n",
    "    svi = SVI(model, guide, optim, EnergyDistance(prior_scale=1/len(r)))\n",
    "    losses = []\n",
    "    for step in range(num_steps):\n",
    "        loss = svi.step(r)\n",
    "        losses.append(loss)\n",
    "        if step % 50 == 0:\n",
    "            median = guide.median()\n",
    "            print(\"step {} loss = {:0.6g}, timescale = {:0.3g}\".format(\n",
    "                step, loss, median[\"timescale\"].item()))\n",
    "    pyplot.plot(losses)\n",
    "    # pyplot.yscale('log')\n",
    "    for name, value in sorted(guide.median().items()):\n",
    "        if value.numel() == 1:\n",
    "            print(\"{} = {}\".format(name, value.squeeze().item()))\n",
    "    add_prediction(model, guide, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Model(\"normal\", \"normal\")\n",
    "train_energy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Model(\"normal\", \"stable\")\n",
    "train_energy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Model(\"studentt\", \"stable\")\n",
    "train_energy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = pyplot.subplots(1 + len(predictions),\n",
    "                            figsize=(8.5, 2 * (1 + len(predictions))),\n",
    "                            sharex=True)\n",
    "axes[0].plot(r, \"k\", lw=0.2)\n",
    "axes[0].set_ylabel(\"returns\")\n",
    "axes[0].set_xlim(0, len(r))\n",
    "for key, ax in zip(sorted(predictions), axes[1:]):\n",
    "    log_h, r_pred = predictions[key]\n",
    "    # ax.plot(log_h.mul(0.5).exp(), lw=0.2)\n",
    "    ax.plot(log_h, lw=0.2)\n",
    "    ax.set_ylabel(\"-\".join(key))\n",
    "ax.set_xlabel(\"day\")\n",
    "pyplot.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
